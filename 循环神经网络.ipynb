{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集:'./datasets/jaychou_lyrics.txt.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载数据集\n",
    "import zipfile\n",
    "\n",
    "def load_dataset(file):\n",
    "    with zipfile.ZipFile(file) as zin:\n",
    "        with zin.open(zin.namelist()[0]) as pf:\n",
    "            dataset = pf.read().decode('utf-8')\n",
    "            # 将数a据集中的换行符换成空格\n",
    "            dataset = dataset.replace('\\r',' ').replace('\\n',' ')\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "字符集长度: 63282\n",
      "想要有直升机 想要和你飞到宇宙去 想要和你融化在一起 融化在宇宙里 我每天每天每天在想想想想著你 这样的甜蜜 让我开始乡相信命运 感谢地心引力 让我碰到你 漂亮的让我面红的可爱女人 温柔的让我心疼的可\n"
     ]
    }
   ],
   "source": [
    "file = './datasets/jaychou_lyrics.txt.zip'\n",
    "dataset = load_dataset(file)\n",
    "print('字符集长度:',len(dataset))\n",
    "print(dataset[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立字符索引\n",
    "index_to_word = list(set(dataset))\n",
    "word_to_index = {word:index for index, word in enumerate(index_to_word)}\n",
    "vocab_size = len(index_to_word) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus_indices(words,word_to_index):\n",
    "    corpus_indices = [word_to_index[word] for word in words]\n",
    "    return corpus_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import nd\n",
    "\n",
    "# 将索引转换成one-hot编码\n",
    "def to_onehot(X,size):\n",
    "    return [nd.one_hot(x,size) for x in X.T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "<NDArray 2x10 @cpu(0)>, \n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
      "<NDArray 2x10 @cpu(0)>]\n"
     ]
    }
   ],
   "source": [
    "print(to_onehot(nd.array([[2,5],[1,3]]),10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型参数\n",
    "# 只含一个隐藏层\n",
    "import mxnet as mn \n",
    "num_input,num_hidden,num_output = vocab_size,256,vocab_size\n",
    "ctx = mn.gpu()\n",
    "\n",
    "def get_params():\n",
    "    def _one(shape):\n",
    "        return nd.ones(scale=0.01,shape=shape,ctx=ctx)\n",
    "    \n",
    "    # 掩藏层参数\n",
    "    w_xh = _one((num_input,num_hidden))\n",
    "    w_hh = _one((num_hidden,num_hidden))\n",
    "    b_h = nd.zeros(num_hidden,ctx=ctx)\n",
    "    \n",
    "    # 输出层参数\n",
    "    w_ho = _one((num_hidden,num_output))\n",
    "    b_o = nd.ones(num_output,ctx=ctx)\n",
    "    \n",
    "    params = [w_xh,w_hh,b_h,w_ho,b_o]\n",
    "    for param in parms:\n",
    "        param.attch_grad()\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "def rnn(inputs,state,params):\n",
    "    w_xh,w_hh,b_h,w_ho,b_o = params\n",
    "    H = state\n",
    "    outputs = []\n",
    "    for x in inputs:\n",
    "        H = nd.relu(nd.dot(x,w_xh) + nd.dot(H,w_hh) + b_h)\n",
    "        output = nd.dot(hidden_output, w_ho) + b_o\n",
    "        outputs.append(output)\n",
    "    return outputs, (H,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义预测函数\n",
    "def predict_rnn(prefix,num_chars,rnn,params,init_rnn_state,\n",
    "               num_hidden,vocab_size,ctx,idx_to_char,char_to_idx):\n",
    "    state = init_rnn_state(1,num_hidden,ctx)\n",
    "    output = [char_to_idx[prefix[0]]]\n",
    "    \n",
    "    for t in range(num_chars + len(prefix)-1):\n",
    "        # 将上一时间步的输出作为当前时间步的输入\n",
    "        X = to_onehot(nd.array([output[-1]], ctx=ctx),vocab_size)\n",
    "        # 计算输出和隐藏状态\n",
    "        (Y,state) = rnn(X,state,params)\n",
    "        # 下一个时间步的输入是prefix里的字符或者当前的最佳预测字符\n",
    "        if t < len(prefix) - 1:\n",
    "            output.append(char_to_idx[prefix[t+1]])\n",
    "        else:\n",
    "            output.append(int(Y[0].argmax(axis=1).asscalar()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机采样\n",
    "import random\n",
    "def data_iter_random(corpus_indices,batch_size,num_steps,ctx=None):\n",
    "    num_examples = (len(corpus_indices) - 1) // num_steps\n",
    "    epoch_size = num_examples // batch_size\n",
    "    \n",
    "    example_indices = list(range(num_examples))\n",
    "    random.shuffle(example_indices)\n",
    " \n",
    "    # 返回从pos开始的长为num_steps的序列\n",
    "    def _data(pos):\n",
    "        return corpus_indices[pos:pos + num_steps]\n",
    "    \n",
    "    for i in range(epoch_size):\n",
    "        batch_indices = example_indices[i* batch_size:(i+1)* batch_size]\n",
    "        X = [_data(j * num_steps) for j in batch_indices]\n",
    "        Y = [_data(j * num_steps + 1) for j in batch_indices]\n",
    "        yield nd.array(X,ctx),nd.array(Y,ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 相邻采样\n",
    "def data_iter_consecutive(corpus_indices,batch_size,num_steps,ctx=None):\n",
    "    nums_in_batch = (len(corpus_indices) - 1) // batch_size\n",
    "    corpus_indices_batch_matrix = nd.array(corpus_indices,ctx=ctx).reshape(batch_size,nums_in_batch) \n",
    "    epoch_size = nums_in_batch // num_steps\n",
    "    for epoch in range(epoch_size):\n",
    "        X = corpus_indices_batch_matrix[:,epoch*num_steps:(epoch+1)*num_steps]\n",
    "        Y = corpus_indices_batch_matrix[:,epoch*num_steps + 1:(epoch+1)*num_steps + 1]\n",
    "        yield X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_iter_random test:\n",
      "X: \n",
      "[[18. 19. 20. 21. 22. 23.]\n",
      " [12. 13. 14. 15. 16. 17.]]\n",
      "<NDArray 2x6 @cpu(0)>\n",
      "Y: \n",
      "[[19. 20. 21. 22. 23. 24.]\n",
      " [13. 14. 15. 16. 17. 18.]]\n",
      "<NDArray 2x6 @cpu(0)>\n",
      "X: \n",
      "[[ 6.  7.  8.  9. 10. 11.]\n",
      " [ 0.  1.  2.  3.  4.  5.]]\n",
      "<NDArray 2x6 @cpu(0)>\n",
      "Y: \n",
      "[[ 7.  8.  9. 10. 11. 12.]\n",
      " [ 1.  2.  3.  4.  5.  6.]]\n",
      "<NDArray 2x6 @cpu(0)>\n",
      "dataset_iter_consecutive test:\n",
      "X: \n",
      "[[ 0.  1.  2.  3.  4.]\n",
      " [14. 15. 16. 17. 18.]]\n",
      "<NDArray 2x5 @cpu(0)>\n",
      "Y: \n",
      "[[ 1.  2.  3.  4.  5.]\n",
      " [15. 16. 17. 18. 19.]]\n",
      "<NDArray 2x5 @cpu(0)>\n",
      "X: \n",
      "[[ 5.  6.  7.  8.  9.]\n",
      " [19. 20. 21. 22. 23.]]\n",
      "<NDArray 2x5 @cpu(0)>\n",
      "Y: \n",
      "[[ 6.  7.  8.  9. 10.]\n",
      " [20. 21. 22. 23. 24.]]\n",
      "<NDArray 2x5 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "# 测试相邻采样\n",
    "seq = list(range(30))\n",
    "print('dataset_iter_random test:')\n",
    "dataset_iter_random = data_iter_random(seq,2,6,ctx=mn.cpu())\n",
    "for x,y in dataset_iter_random:\n",
    "    print('X:',x)\n",
    "    print('Y:',y)\n",
    "    \n",
    "print('dataset_iter_consecutive test:')\n",
    "dataset_iter_consecutive = data_iter_consecutive(seq,2,5,ctx=mn.cpu())\n",
    "for x,y in dataset_iter_consecutive:\n",
    "    print('X:',x)\n",
    "    print('Y:',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  mxnet.gluon import loss as gloss\n",
    "from mxnet import autograd\n",
    "# 模型训练\n",
    "def train_and_predict_rnn(rnn,get_params,init_rnn_state,num_hidden,vocab_size,\n",
    "                         ctx,corplus_indices,idx_to_char,char_to_idx,is_random_iter,\n",
    "                         num_epochs,num_steps,,batch_size,learning_rate,clipping_theta,\n",
    "                         pred_period,pred_len,prefixes):\n",
    "    # 数据采样\n",
    "    if is_random_iter:\n",
    "        data_iter_fn = data_iter_random\n",
    "    else:\n",
    "        data_iter_fn = data_iter_consecutive\n",
    "    # 获取模型参数\n",
    "    params = get_params()\n",
    "    # 损失函数\n",
    "    loss= gloss.SoftmaxCrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        if not is_random_iter: # 若使用相邻采样，在epoch开始时初始化隐藏状态\n",
    "            state = init_rnn_state(batch_size,num_hidden,ctx)  #上一次的输出\n",
    "        \n",
    "        data_iter = data_iter_fn(corplus_indices,batch_size,num_steps,ctx)\n",
    "        for X,Y in data_iter:\n",
    "            if is_random_iter: # 如果是随机采样，在每个小批量更新前初始化隐藏状态\n",
    "                state = init_rnn_state(batch_size,num_hidden,ctx)  #上一次的输出\n",
    "            else: # 否则需要使用detach从计算图分离隐藏状态\n",
    "                for s in state:\n",
    "                    s.detach()\n",
    "            with autograd.record():\n",
    "                inputs = to_onehot(X,vocab_size)\n",
    "                # outputs有num_steps个形状为(batch_size,vocab_size)的矩阵\n",
    "                (outputs,state) = rnn(inputs,state,params)\n",
    "                # 连接之后形状为(num_steps * batch_size, vocab_size)\n",
    "                outputs = nd.concat(*outputs,dim=0)\n",
    "                # y的形状是(batch_size,num_steps),转置后变成长度为batch_size * num_step的向量，\n",
    "                # 这样跟输出的行一一对应\n",
    "                y = Y.T.reshape((-1,))\n",
    "                l = loss(putputs,y).mean()\n",
    "            l.backward()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
