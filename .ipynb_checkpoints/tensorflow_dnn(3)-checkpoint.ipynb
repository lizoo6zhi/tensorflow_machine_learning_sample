{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "练习:\n",
    "\n",
    "    创建一个新的DNN，重用前一个模型的所有预先训练好的隐藏层，冻结它们，并用一个新的替换softmax输出层。\n",
    "    让我们加载最好的模型图，并处理我们需要的所有重要操作。注意，我们不创建一个新的softmax输出层，而是重用现有的输出层(因为它具有与现有输出相同的输出数量)。我们将在训练前重新初始化它的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"X:0\", shape=(?, 784), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "restore_saver = tf.train.import_meta_graph('./model/my_best_mnist_model_0_to_4.meta')\n",
    "\n",
    "X = tf.get_default_graph().get_tensor_by_name('X:0')\n",
    "Y = tf.get_default_graph().get_tensor_by_name('Y:0')\n",
    "#logits = tf.get_default_graph().get_tensor_by_name(\"logits:0\")\n",
    "y_proba = tf.get_default_graph().get_tensor_by_name('y_proba:0')\n",
    "loss = tf.get_default_graph().get_tensor_by_name('loss:0')\n",
    "accuracy = tf.get_default_graph().get_tensor_by_name('accuracy:0')\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"hidden1_out|logits\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam2\")\n",
    "training_op = optimizer.minimize(loss, var_list=output_layer_vars)\n",
    "\n",
    "correct = tf.equal(tf.argmax(y_proba,1),tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "five_frozen_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#将Y_train的独热编码转换成数字标识\n",
    "def transform_number(Y):\n",
    "    return np.array([np.argmax(element) for element in Y])\n",
    "\n",
    "def transform_onehot(Y):\n",
    "    _classes = np.unique(Y)\n",
    "    n_outputs = len(_classes)\n",
    "    _classes_to_index = {label:index for index,label in enumerate(_classes)}\n",
    "    labels = np.array([_classes_to_index[element] for element in Y],dtype=np.int32)\n",
    "    onehot_labels = np.zeros((len(labels),n_outputs))\n",
    "    for i in range(len(labels)):\n",
    "        onehot_labels[i][labels[i]] = 1\n",
    "    return onehot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data',one_hot=True)\n",
    "x_train,y_train = mnist.train.images,mnist.train.labels\n",
    "x_test,y_test = mnist.test.images,mnist.test.labels\n",
    "\n",
    "#创造6-9训练数据集和测试数据集\n",
    "y_train_numbers = transform_number(y_train)\n",
    "x_train6 = x_train[y_train_numbers >= 5]\n",
    "y_train6_numbers = y_train_numbers[y_train_numbers >= 5]\n",
    "y_train6 = transform_onehot(y_train6_numbers)\n",
    "\n",
    "y_test_numbers = transform_number(y_test)\n",
    "x_test6 = x_test[y_test_numbers >= 5]\n",
    "y_test6_numbers = y_test_numbers[y_test_numbers >= 5]\n",
    "y_test6 = transform_onehot(y_test6_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/my_best_mnist_model_0_to_4\n",
      "0\tValidation loss: 0.327238\tBest loss: 0.327238\tAccuracy: 90.31%\n",
      "1\tValidation loss: 0.220742\tBest loss: 0.220742\tAccuracy: 92.92%\n",
      "2\tValidation loss: 0.218472\tBest loss: 0.218472\tAccuracy: 93.09%\n",
      "3\tValidation loss: 0.201474\tBest loss: 0.201474\tAccuracy: 93.25%\n",
      "4\tValidation loss: 0.195634\tBest loss: 0.195634\tAccuracy: 93.79%\n",
      "5\tValidation loss: 0.190752\tBest loss: 0.190752\tAccuracy: 93.62%\n",
      "6\tValidation loss: 0.206903\tBest loss: 0.190752\tAccuracy: 93.21%\n",
      "7\tValidation loss: 0.188464\tBest loss: 0.188464\tAccuracy: 93.81%\n",
      "8\tValidation loss: 0.191090\tBest loss: 0.188464\tAccuracy: 93.83%\n",
      "9\tValidation loss: 0.227888\tBest loss: 0.188464\tAccuracy: 92.51%\n",
      "Total training time: 3.6s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "n_epochs = 10\n",
    "batch_size = 120\n",
    "\n",
    "max_checks_without_progress = 10\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./model/my_best_mnist_model_0_to_4\")\n",
    "    t0 = time.time()\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(x_train6))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(x_train6) // batch_size):\n",
    "            X_batch, y_batch = x_train6[rnd_indices], y_train6[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, Y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: x_test6, Y: y_test6})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = five_frozen_saver.save(sess, \"./my_mnist_model_5_to_9_five_frozen\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "    t1 = time.time()\n",
    "    print(\"Total training time: {:.1f}s\".format(t1 - t0))\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     five_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_five_frozen\")\n",
    "#     acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "#     print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
